{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see how to use bayesian on multi-class classification/discrimination.\n",
    "\n",
    "Import class sklearn.naive_bayes.MultinomialNB for Multinomial logistic regression (logistic regression of multi-class).\n",
    "\n",
    "If you want to classify binary classes, it is better to use BernoulliNB.\n",
    "\n",
    "I will also compare accuracy for using BOW and TF-IDF vectorizing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import re\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some function to help us for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear string\n",
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n",
    "# because of sklean.datasets read a document as a single element\n",
    "# so we want to split based on new line\n",
    "def separate_dataset(trainset):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        # python3, if python2, just remove list()\n",
    "        data_ = list(filter(None, data_))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included 6 classes in local/\n",
    "1. adidas (wear)\n",
    "2. apple (electronic)\n",
    "3. hungry (status)\n",
    "4. kerajaan (government related)\n",
    "5. nike (wear)\n",
    "6. pembangkang (opposition related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Classes: ['adidas', 'apple', 'hungry', 'kerajaan', 'nike', 'pembangkang']\n",
      "# of Samples: 25292\n",
      "# of Samples: 25292\n"
     ]
    }
   ],
   "source": [
    "# you can change any encoding type\n",
    "trainset = sklearn.datasets.load_files(container_path = 'local', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset)\n",
    "print (\"List of Classes: %s\" %trainset.target_names)\n",
    "print (\"# of Samples: %s\" %len(trainset.data))\n",
    "print (\"# of Samples: %s\" %len(trainset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change n to see different samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Report 1MDB negotiations over missing funds breaks down Mkini\n",
      "Class: pembangkang\n"
     ]
    }
   ],
   "source": [
    "n=111\n",
    "print(\"Sentence: %s\" %trainset.data[n])\n",
    "print(\"Class: %s\" %trainset.target_names[trainset.target[n]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train (80%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_Y, test_Y = train_test_split(trainset.data, trainset.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to change data into BOW vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer().fit(train_data) # create and train a bow verctorizer using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test Naive Bayes using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set: 0.851749357581\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.96      0.76      0.85       311\n",
      "      apple       0.82      0.90      0.86       450\n",
      "     hungry       0.87      0.94      0.90      1034\n",
      "   kerajaan       0.86      0.81      0.83      1417\n",
      "       nike       0.89      0.80      0.84       298\n",
      "pembangkang       0.82      0.85      0.83      1549\n",
      "\n",
      "avg / total       0.85      0.85      0.85      5059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_train_X = bow.transform(train_data)\n",
    "bow_test_X = bow.transform(test_data)\n",
    "\n",
    "bayes_multinomial = MultinomialNB().fit(bow_train_X, train_Y)\n",
    "predicted = bayes_multinomial.predict(bow_test_X)\n",
    "print('accuracy validation set: %s' %np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to change data into TF-IDF vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# must get data from BOW first\n",
    "tfidf = TfidfTransformer().fit(bow_train_X) # create and train a tfidf verctorizer using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Naive Bayes using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set: 0.807076497331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.98      0.59      0.74       311\n",
      "      apple       0.96      0.61      0.75       450\n",
      "     hungry       0.83      0.91      0.87      1034\n",
      "   kerajaan       0.86      0.81      0.83      1417\n",
      "       nike       0.92      0.61      0.73       298\n",
      "pembangkang       0.71      0.88      0.78      1549\n",
      "\n",
      "avg / total       0.83      0.81      0.80      5059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# must get data from BOW first\n",
    "tfidf_train_X = tfidf.transform(bow_train_X)\n",
    "tfidf_test_X = tfidf.transform(bow_test_X)\n",
    "\n",
    "bayes_multinomial = MultinomialNB().fit(tfidf_train_X, train_Y)\n",
    "predicted = bayes_multinomial.predict(tfidf_test_X)\n",
    "print('accuracy validation set: %s' %np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
